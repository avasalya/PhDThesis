% ====================================================================== %
%                           State-of-the-art
% ======================================================================= %

{\color{blue}\chapter{State of the art}\label{sota}}


Robotic platforms with a floating base and whose overall shape and configuration resemble that of a human body (child or adult) is called humanoid robots. A humanoid robot (such as Russian space robot `Fedor', `iCub' from RobotCub, `Nao' from Aldebaran, Boston Dynamics's `Atlas' or domestic helper HRP series robots by Kawada industries) generally consists of a head, two arms, a torso and \textit{two legs}.

Humanoid robotics design takes inspiration directly from human capabilities. Previous human-robot interaction studies~\cite{huber2008human, strabala2013toward, shibata1995experimental, Chaminade:JPP:2009}, have shown that the human acceptance of the robot co-worker during a task increases when the robot appears and behaves human-like during an interactive task. 

In all of our studies, we used \textit{biped} humanoid robot HRP-2Kai~\cite{Kaneko:RAS_ICHR:2015} as the robot co-worker who has two arms and two legs, a head and a torso. HRP-2Kai is a life-size biped humanoid robot which is 154 cm tall, has 32 degree-of-freedoms and weighs about 58 kg. It was designed and manufactured by the Kawada Industries, Inc in collaboration with AIST under Humanoid Robotics Project (HRP).


\section{Human-robot interaction (HRI)}

Human-robot interaction is an emerging field which deals with the study and research of interactions between humans and robots. HRI research studies aim to model and design robotic platforms, including improvements of algorithms and control systems based on human partners' expectations during interactions such as remote assistance or collaborative work among co-workers. These interactions can be divided into two general categories depending on the distance between human and robot~\cite{goodrich2008human}. Interactions that often carry out at a safer distance and without a need of physical touch (direct or indirect via an object) between humans and robots are termed as \textit{non-physical} HRI, while interactions that often require humans and robots to be in proximity such as during a physical manipulative event(s) with a goal of achieving a task together, that may involve touch or contact, transfer, assistance or collaborations are termed as \textit{physical} HRI or pHRI. These interactions can also be further distinguished based on the applications that require social interactions~\cite{tzafestas2016human, Chaminade:JPP:2009} or physical manipulations during a task. The studies conducted in the 1$^\text{st}$ part of this thesis are mostly motivated by social interactions between human and humanoid robot co-workers, which deal with the implicit behavioural and cognitive aspects of interactions. While the 2$^\text{nd}$ part of this thesis is motivated by the physical manipulations of an object between human and humanoid robot co-workers nearby. Human-robot social interaction is a vast field in itself; therefore we will not be discussing it in detail here, rather our focus lies on one particular behavioural aspect of social interaction, i.e. `motor contagion'.


%review paper-Chaminade:JPP:2009: Social cognitive neuroscience and humanoid robotics


\subsection{Motor contagion}\label{motor contagions}

When an individual performs an action followed by the observation of someone's action, implicit behavioural effects such as motor contagions causes certain features (kinematics parameters, goal or outcome) of that action to become similar to the observed action. Past two decades of several studies in sports and psychology have examined and reported various cases of motor contagions in human behaviours, most of which are induced by the observation of other humans and in fact robots as well~\cite{Becchio:BJN:2007, Hillebrandt:SciReports:2014, Chaminade:BRB:2008, Blakemore:Neuropsychologia:2005, Fadiga:JNeuroPhys:1995, Ganesh:Springer:2015, Sciutti:IJSR:2012, Prinz:EJPAP:1997, edwards2003motor, gray2011hitting}. Due to increasing usage of robots as co-workers in today's industries, it is of uttermost importance to understand the effects of robots on nearby working human co-workers. In these industrial scenarios where human-robot dyad would eventually share a workspace and possibly collaborate during a task, by understanding how the robot behaviour could affect human behaviour can be proven crucial and beneficial in optimizing and designing robot control to ensure that robot would be perceived well and won't cause harm or disturbance to the human co-workers. While where ethically valid, robots may also be useful to modulate human co-worker behaviour/performance for the productivity of the task.

In our studies, specifically in Chapter~\ref{distinct motor contagion}, we divided motor contagions into two categories depending on \textit{when} they are induced relative to the observation of the action performed. We called motor contagions as \textit{on-line} contagions, that are induced \textit{during} the observation of actions performed by another human or robot co-worker. One example of \textit{on-line} contagions would be the study performed by~\cite{Kilner:CurBio:2003}, where they analyzed human participant movements variance when he/she observed spatially congruent or in-congruent movements made by another human or robot. Their findings suggest that \textit{on-line} contagions are induced only during the observation of human but not with a robot when it made non-biological movements.

While on the other hand, \textit{off-line} contagions effects are induced \textit{after} the observation of action either by human or robot. One example of this kind of contagions would be the study by~\cite{Bisio:PlosOne:2014}, where they analyzed the change in participant's hand movements velocity in a task performed with and without an object, \textit{after} observing the same movement being performed by a human or a humanoid robot. The results of this study suggest that the participant's hand velocity was subsequently affected after the human and humanoid robot (biological) movement observation.  

However, both \textit{on-line} contagions~\cite{Kupferberg:Methods:2009, Oztop:RAS_ICHR:2004, Chaminade:JPP:2009, Kupferberg:PlosOne:2012, Brass:ActaPsych:2001, Press:CBR:2005} and \textit{off-line} contagions~\cite{Noy:B&C:2009, Kilner:SocialNeuro:2007, Bisio:PlosOne:2010, heyes2011automatic, Ikegami:SciReport:2014, Ikegami:elife:2018} have been largely studied,  but in all these previous studies, researchers have focused on either type of motor contagions and never examined or analyzed them together. Hence, it is still unclear, if and how \textit{on-line} and \textit{off-line} motor contagions are different from each other in terms of the human movement behavioral features they affect and the magnitude of these effects. 

To address this issue, in Chapter~\ref{distinct motor contagion}, we designed a paradigm inspired by the industrial co-worker setting and examined the differences between the induced \textit{on-line} and \textit{off-line} contagions in participants by the observation of the same movements performed by both human and humanoid robot co-worker. In our empirical repetitive industrial task, we carefully varied the behaviour of the co-worker (human and humanoid robot) and analyzed the induced \textit{on-line} and \textit{off-line} motor contagions in human participant's behaviour.


\subsection{Motor contagion: a social influencer}\label{influence performance}

While the studies of the human-robot interaction on motor contagions are sparse, the results from them suggest that motor contagions due to observation of robots affect human movement velocity~\cite{Noy:B&C:2009, Kilner:SocialNeuro:2007, Bisio:PlosOne:2010, Bisio:PlosOne:2014}, or the human movement variance~\cite{Kupferberg:Methods:2009, Kupferberg:PlosOne:2012, Brass:ActaPsych:2001, Press:CBR:2005}, but latter studies have reported changes in arguably abstract tasks. Also, former studies which showed changes in movement velocity have not examined how participant movement variance changes with the change in movement velocity. On the other hand, precision in movements along with speed is the key in most industrial tasks; hence it is necessary to consider both task accuracy and task speed (or rather say frequency in case of a repetitive task) to accurately measure the performance in a task. Therefore it is interesting to examine how both of these parameters (speed and variance) of human movements could be affected by observing a humanoid robot co-worker and whether it is possible to quantify the affected \textit{performance} of human co-worker due to motor contagions.

Furthermore, some studies in the past highlight contradictory evidence that robot co-worker physical form does~\cite{Chaminade:JPP:2009} or does not ~\cite{Kupferberg:PlosOne:2012} affect the human movement's variance. Though it is unclear regarding the movement speed and hence performance, finally, it remains to be seen whether and how these effect of motor contagions on the task performance are to be modulated due to the prior human experience with robots in general. This issue with performance \texttt{Vs} experience could be proven crucial in understanding how the continued exposure of robot co-worker would be on human performance.

We addressed these issues, by further extending our work from Chapter~\ref{distinct motor contagion} and by exploiting the behavioral effects of motor contagions on human participant's movement speed (frequency) and as well as their task accuracy, after the observation of same movement by a humanoid robot co-worker and report these findings in detail in Chapter~\ref{more than just co-workers}. We also reported our findings on the effect of the physical form of humanoid robots as well as the magnitude of these effects with human participants prior experience with robots.



%\clearpage

\section{Physical human-robot interaction (pHRI)}

Interactions that often require humans and robots to be in close proximity such as during a physical manipulative event(s) to achieve a task together that may involve touch or contact, transfer, assistance or collaborations are considered as \textit{physical} human-robot interactions or just pHRI. As mentioned earlier, 2$^\text{nd}$ part of this thesis is motivated by the physical manipulations of the object between human and humanoid robot co-workers nearby. 

The usage of robots in personal as well as in commercial sectors have evolved significantly in recent years. Moreover, robot working and sharing a workspace with humans as co-workers in these sectors can often lead to opportunities where human and robot have to work together and collaborate within a confined space. One of the most often tasks that occurs during this human-robot collaborative interaction is the handing-over or exchange of an object such as tools in industrial scenarios or a glass of water in personal scenarios from either robot to human or vice-versa. This problem of object handover is a complex collaborative task that occurs seamlessly and effortlessly during the physical interaction between the human dyads, often without any explicit communication. Some well-known object handover examples such as ``handing over a glass of water to a patient by the caregiver'', ``sharing a tool to a mechanic'', ``handing a business card to a client'' and many more are often fundamental in our society. These natural yet simple physical interactive tasks occur flawlessly multiple times between the human dyads daily and under several scenarios in space and time. Although handovers are fluent phase-less natural events between human-human interactions, during the human-robot dyad interactions, the handover of an object is a challenging task and often regarded as unnatural (non-biological) behaviour. 

This unnatural behaviour mainly arises due to the lack of responsiveness and unreliability of the robot co-worker, and the safety issues of the human co-worker during the interaction. In the previous human-robot interaction studies~\cite{huber2008human, strabala2013toward, shibata1995experimental} and also in our work Chapter~\ref{more than just co-workers}, we have shown that the human acceptance of the robot co-worker during a task increases when the robot appears and behaves human-like, especially during a collaborative, interactive task. Therefore again in our next study, we primarily chose to consider humanoid robot HRP-2Kai as the robot co-worker. In Chapter~\ref{handover chapter}, we mainly focused on solving the problem of intuitive and proactive bi-directional object handover between human and a biped humanoid robot dyad using robot Whole-Body Control (WBC)~\cite{bouyarmane2018quadratic, ladder-HRP-2Kai, bouyarmane2011using, sentis2006whole}. We formulated our handover problem by taking inspiration and insights from the previous works in the field of object handover between human-human and human-robot dyads in general. We will now discuss some of those significant previous research works.

%strabala paper important for handover introduction
\subsection{Previous handover studies}

\textbf{Overview:} Object handover being the most common interactive task and knowing its significance in daily life; it is evident that object handovers have been widely studied by the researchers both during the interactions of human-human and human-robot dyads. These past studies related to object handovers can be categorized under three main research topics. The prediction and estimation of human motion towards the handover location and concurrent robot motion planning towards that location~\cite{huber2008Indus, li2015predicting, waldhart2015planning, mainprice2012sharing, vahrenkamp2009humanoid, kim2004advanced, mainprice2010planning}. To understand and codify the interaction forces that is applied on the object between the dyads during the handover~\cite{chan2014implementation, medina2016human, chan2013human, sadigh2009safe, nagata1998delivery}. To effectively minimizing the overall handover duration between the dyads~\cite{nemlekarprompt, cakmak2011using, huber2008human, nemlekar2019object}.

\textbf{Studies on handover motion:} In order for the human-robot object handovers to be proactively intuitive, the robot must be able to predict and estimate the human motion in advance. Instead of simply waiting for the object to be presented by the human at the handover location, the robot must proactively plan its motion by observing and predicting next human motion and arrive at the human chosen handover location approximately at the same time. ~\cite{li2015predicting} have compared several mathematical position prediction models where human is always \textit{giver} and robot is always \textit{receiver}. Thanks to these models, their preliminary results show an overall reduction in handover duration period. While~\cite{perez2015fast, sheikholeslami2018prediction, vogt2017system, kupcsik2016learning}  have developed human hand motion prediction model by gaining insights learned from the human-human object handover studies. However, since specifically developing alone position prediction model is not the main focus of our study; therefore, we primarily decided to accommodate a simple method to predict the human hand motion using~\textit{constant velocity} based model. We have further discussed this in detail in Chapter \ref{handover chapter}.

\textbf{Studies on handover configuration:} Although predicting handover location is not enough, the robot must also be able to find the most appropriate configuration to grasp (as \textit{receiver}) or release (as \textit{giver}) the object, based on the comfort and requirement of the human co-worker. Therefore for an intuitive and smooth handover of an object, the robot should relatively orient its hand (in our case gripper as the end-effector) and configure accordingly. Though there are several possible configurations to handover an object, the robot must determine the correct configuration of its end-effector during the handover which is suitable and natural for the human. Moreover, according to to~\cite{cakmak2011human}, we humans prefer handover of an object in its default orientation.~\cite{aleotti2012comfortable} work suggests that robot takes human comfort and convenience under consideration to find the appropriate orientation during the handover, which they gave a higher score based on the appropriateness and safety.~\cite{vogt2018one} Showcased human-robot object handover using imitation learning based on human-human demonstration. The robot relies on the posture of the human participant to determine the pose of object handover. ~\cite{kim2004advanced} proposed object handover and grasp planning method that incorporates cultural etiquette (one-hand, two-hand, two-hand mid-air) based on the object's function, object shape and safety of both human and robot. While~\cite{vezzani2017novel, song2013predicting, micelli2011perception} estimated the appropriate handover orientation using a 3D image of the object and by tracking human hand.~\cite{lopez2006grasp} Introduced a simulated model planner to grasp the unknown objects during the interactive manipulative tasks. However even though the handover motion can be planned or optimized online but it is still essential for the robot to promptly adapt to changes in the handover location during the interaction, especially at the time of handover or exchange of the object.

\textbf{Studies on interaction forces:} Previous studies on the forces during these handover interactions analyzed the relationship between grip force (applied on the object by the human) and the load force (object weight shared by the robot).~\cite{mason2005grip} findings suggest a gradual change in the grip force while the human dyad implicitly share the load force during the transfer of the object.~\cite{chan2013human} Investigated the grip forces applied on an object while it is being exchanged between the human-human dyad during a handover. They found a linear relationship between these forces, suggesting that the \textit{giver} is responsible for safety of object during the transfer and \textit{receiver} is responsible for the timing of handover.~\cite{nagata1998delivery} demonstrated a grasping system based on the 6DOF wrench (force and torque) feedback that first acknowledges the stable and secure grasp on the object by the human, only after that the object is released by the robot.~\cite{medina2016human} Learned from the insights during the human dyad handovers and developed a dynamic force controller which significantly reduces the internal forces between the human-robot dyad compared to the traditional threshold-based controller. Inspired by the human object grasping, \cite{sadigh2009safe} designed a robotic grasping controller with minimal normal forces while grasping an object to make sure it does not slip.~\cite{parastegari2018failure} proposed object re-grasping controller in case of false grasping. \cite{kupcsik2016learning} presented a dynamic object handover controller based on the contextual policy search, where the robot learns about the object handover while interacting with the human and dynamically adapts to the motion of the human.~\cite{chan2014implementation} Designed a controller to estimate the applied grip force and load force by measuring the joint position/angle errors on a compliant underactuated humanoid hand. However, in most of these studies, knowledge of object mass is a prerequisite. In our approach, knowing object mass in advance is optional as it can be calculated during the handover routine, but we do rely on knowing the object physical, structural properties.

\textbf{Studies on robot motion planning:} Majority of studies related to human-robot object handovers were carried out in the past with traditional robotic arm manipulators attached to either a stationary-base or to a wheeled-base mobile robotic system~\cite{medina2016human, vogt2018one, huber2008Indus, kupcsik2016learning, cakmak2011human} and latter studies are often related to the robot motion planning and navigation in an ample space and lacks proactive behaviour using `biped' locomotion of a humanoid robot which is capable of walking as human does. To the best of our knowledge, bi-directional object handover with biped walking has not been considered in the previous works on the human-robot dyad object handover. However~\cite{vezzani2017novel, chan2014implementation} have utilized biped walking capable humanoid robots in their studies but without considering locomotion. Therefore for the robot to be sufficiently proactive, we believe it is crucial to consider the possibility of the robot taking a step to handover or exchange an object with the human co-worker, in scenarios where short-distance travel is required. We do not focus on the problem of motion planning or navigation in a large cluttered environment~\cite{mainprice2012sharing, vahrenkamp2009humanoid, kim2004advanced}. However, instead, we concentrated our efforts to solve and optimize object handover problem which requires immediate shared efforts between human-robot dyad in a small space where few steps are necessary and enough for a comfortable and convenient object handover. We proposed simple but effective methods to take advantage of a biped humanoid robot and deal with the problem of bi-directional object handover using robot whole-body control. Though there are many state-of-the-art methods available to generate walking patterns for a biped humanoid robot, however, the study done in Chapter~\ref{handover chapter} primarily adopted the walking pattern generator (WPG) which was designed and tested in our group~\cite{ kajita20013d, caron2016humanoids} along with its native stabilizer~\cite{kajita2010biped, caron2018stair}.



\subsection{Proactive handover formulation}

We concentrated our efforts towards developing a simple yet robust and efficient handover controller for bi-directional object exchange and transfer between the human and the robot co-workers using robot Whole-Body Control (WBC). WBC allows simultaneous execution of several tasks at once, for example, a humanoid robot capable of using and configuring either single or both hands during the handover and manipulation of the object and at the same time, being proactive and capable of taking few steps or more during the exchange and transfer of the object. WBC exploits the full potential of the entire floating based robot body and allows interaction with the environment using multi-contact strategies~\footnote{as explained by the IEEE Technical Committee on Whole-Body Control}~\cite{ladder-HRP-2Kai}. Several previous studies such as~\cite{strabala2013toward, huber2008human} have treated object handover routine as a non-continuous entity and analyzed the routine of handover individually into three main sub-tasks â€” approach, deliver and retreat. However, we take a similar approach as one mentioned in the~\cite{medina2016human, nemlekarprompt} and treat the object handover between human and humanoid robot co-worker as one-shot continuous fluid motion.

\cite{vahrenkamp2009humanoid, vezzani2017novel} and~\cite{kim2004advanced} have adapted object handover and manipulation using dual-arm motion planning but did not consider robot locomotion. Also, in previous studies, dual-arm manipulation is limited between robot arms only without involving human co-worker. Our handover controller, however, enables both human and robot to utilize either single or both hands simultaneously during the object handover routine.

We initially formulate our handover problem under the scenario of human-robot bi-directional object handover using human right hand and robot left end-effector. We mainly focus on three important key features during the human humanoid robot object handover routine ---the \textit{timing}(s) of handover, the \textit{pose} of handover and the \textit{magnitude} of the interaction forces between human hand(s) and humanoid robot end-effector(s). Basically we answer the following questions in Chapter~\ref{handover chapter}, ---\textbf{when} (\textit{timing}), \textbf{where} (\textit{position in space}), \textbf{how} (\textit{orientation and interaction forces}) of the handover.


Later, we present a generalized handover controller, where both human and the robot is capable of selecting either of their hand to handover and exchange the object. Furthermore, by utilizing the WBC configuration, our handover controller can allow the robot to use both hands (bi-manual) simultaneously during the object handover, depending upon the shape and size of the object that needs to be transferred. Our bi-directional handover controller is intuitive; also, it is adaptable to several objects of distinguishable physical properties (shape, size and mass). Our handover controller only needs the pertinent information of the environment (object), mainly the object's shape and size information, though knowing the mass of the object is not essential in the beginning.

Finally, we explored the full capabilities of a biped humanoid robot and added a scenario where the robot needs to proactively take a few steps to handover or exchange the object between its human co-worker. We have tested this scenario during both when human-robot dyad uses either single or both hands simultaneously. Note that by proactive nature of robot, we meant that our approach did not require a robot to be trained from the human operator, rather robot behaviour should be able to meet the human co-worker's expectations.


\clearpage
